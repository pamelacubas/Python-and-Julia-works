{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194aa0df",
   "metadata": {},
   "source": [
    "## Causal Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261f475",
   "metadata": {},
   "source": [
    "## 1. How the tree was built?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbf424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install econml\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import econml\n",
    "# Main imports\n",
    "from econml.orf import DMLOrthoForest, DROrthoForest\n",
    "from econml.dml import CausalForestDML\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCVWrapper, WeightedLasso, WeightedLassoCV\n",
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "# Helper imports\n",
    "from itertools import product\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from econml.grf import RegressionForest\n",
    "%matplotlib inline\n",
    "import patsy\n",
    "import seaborn as sns\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a7fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schoolid</th>\n",
       "      <th>Z</th>\n",
       "      <th>Y</th>\n",
       "      <th>S3</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>XC</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081602</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.385869</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398184</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.175037</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884583</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.423366</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.197092</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10388</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141698</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10389</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.351565</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10391 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      schoolid  Z         Y  S3  C1  C2  C3  XC        X1        X2        X3  \\\n",
       "0           76  1  0.081602   6   4   2   1   4  0.334544  0.648586 -1.310927   \n",
       "1           76  1 -0.385869   4  12   2   1   4  0.334544  0.648586 -1.310927   \n",
       "2           76  1  0.398184   6   4   2   0   4  0.334544  0.648586 -1.310927   \n",
       "3           76  1 -0.175037   6   4   2   0   4  0.334544  0.648586 -1.310927   \n",
       "4           76  1  0.884583   6   4   1   0   4  0.334544  0.648586 -1.310927   \n",
       "...        ... ..       ...  ..  ..  ..  ..  ..       ...       ...       ...   \n",
       "10386        1  0  0.423366   7   4   2   1   3  1.185986 -1.129889  1.009875   \n",
       "10387        1  0 -0.197092   7   4   2   1   3  1.185986 -1.129889  1.009875   \n",
       "10388        1  0  0.141698   2  15   1   1   3  1.185986 -1.129889  1.009875   \n",
       "10389        1  0 -0.351565   5   4   1   1   3  1.185986 -1.129889  1.009875   \n",
       "10390        1  0  0.211240   5   1   2   1   3  1.185986 -1.129889  1.009875   \n",
       "\n",
       "             X4        X5  \n",
       "0      0.224077 -0.426757  \n",
       "1      0.224077 -0.426757  \n",
       "2      0.224077 -0.426757  \n",
       "3      0.224077 -0.426757  \n",
       "4      0.224077 -0.426757  \n",
       "...         ...       ...  \n",
       "10386  1.005063 -1.174702  \n",
       "10387  1.005063 -1.174702  \n",
       "10388  1.005063 -1.174702  \n",
       "10389  1.005063 -1.174702  \n",
       "10390  1.005063 -1.174702  \n",
       "\n",
       "[10391 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_all = pd.read_csv(\"synthetic_data.csv\")\n",
    "data_all[\"schoolid\"] = pd.Categorical(data_all[\"schoolid\"])\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = data_all.iloc[:,1:]\n",
    "school_id = pd.to_numeric(data_all[\"schoolid\"])\n",
    "school_mat = np.zeros([data_all.shape[0],max(school_id)])\n",
    "\n",
    "for i in range(data_all.shape[0]):\n",
    "    school_mat[i,data_all[\"schoolid\"][i]-1] = 1\n",
    "    \n",
    "school_size = school_mat.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529defe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schoolid</th>\n",
       "      <th>Z</th>\n",
       "      <th>S3</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>XC</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10388</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10389</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.185986</td>\n",
       "      <td>-1.129889</td>\n",
       "      <td>1.009875</td>\n",
       "      <td>1.005063</td>\n",
       "      <td>-1.174702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10391 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      schoolid  Z  S3  C1  C2  C3  XC        X1        X2        X3        X4  \\\n",
       "0           76  1   6   4   2   1   4  0.334544  0.648586 -1.310927  0.224077   \n",
       "1           76  1   4  12   2   1   4  0.334544  0.648586 -1.310927  0.224077   \n",
       "2           76  1   6   4   2   0   4  0.334544  0.648586 -1.310927  0.224077   \n",
       "3           76  1   6   4   2   0   4  0.334544  0.648586 -1.310927  0.224077   \n",
       "4           76  1   6   4   1   0   4  0.334544  0.648586 -1.310927  0.224077   \n",
       "...        ... ..  ..  ..  ..  ..  ..       ...       ...       ...       ...   \n",
       "10386        1  0   7   4   2   1   3  1.185986 -1.129889  1.009875  1.005063   \n",
       "10387        1  0   7   4   2   1   3  1.185986 -1.129889  1.009875  1.005063   \n",
       "10388        1  0   2  15   1   1   3  1.185986 -1.129889  1.009875  1.005063   \n",
       "10389        1  0   5   4   1   1   3  1.185986 -1.129889  1.009875  1.005063   \n",
       "10390        1  0   5   1   2   1   3  1.185986 -1.129889  1.009875  1.005063   \n",
       "\n",
       "             X5  \n",
       "0     -0.426757  \n",
       "1     -0.426757  \n",
       "2     -0.426757  \n",
       "3     -0.426757  \n",
       "4     -0.426757  \n",
       "...         ...  \n",
       "10386 -1.174702  \n",
       "10387 -1.174702  \n",
       "10388 -1.174702  \n",
       "10389 -1.174702  \n",
       "10390 -1.174702  \n",
       "\n",
       "[10391 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_all3= data_all.drop(['Y'], axis=1)\n",
    "data_all3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'Z ~ schoolid + S3+ C1+ C2+ C3+ XC+ X1+ X2+ X3+ X4+ X5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce11b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      Z   No. Observations:                10391\n",
      "Model:                            GLM   Df Residuals:                    10311\n",
      "Model Family:                Binomial   Df Model:                           79\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -6504.4\n",
      "Date:                Thu, 06 Jun 2024   Deviance:                       13009.\n",
      "Time:                        14:39:36   Pearson chi2:                 1.04e+04\n",
      "No. Iterations:                   100   Pseudo R-squ. (CS):            0.01016\n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -1.0478      0.140     -7.483      0.000      -1.322      -0.773\n",
      "schoolid[T.2]     -0.0306      0.200     -0.153      0.878      -0.422       0.361\n",
      "schoolid[T.3]     -0.0798      0.162     -0.493      0.622      -0.397       0.237\n",
      "schoolid[T.4]      0.0336      0.159      0.211      0.833      -0.279       0.346\n",
      "schoolid[T.5]     -0.0606      0.202     -0.299      0.765      -0.457       0.336\n",
      "schoolid[T.6]      0.2010      0.181      1.111      0.266      -0.153       0.555\n",
      "schoolid[T.7]      0.0377      0.195      0.193      0.847      -0.344       0.419\n",
      "schoolid[T.8]      0.0385      0.203      0.189      0.850      -0.360       0.437\n",
      "schoolid[T.9]     -0.2585      0.293     -0.884      0.377      -0.832       0.315\n",
      "schoolid[T.10]    -0.0589      0.163     -0.362      0.717      -0.378       0.260\n",
      "schoolid[T.11]    -0.1768      0.412     -0.429      0.668      -0.984       0.630\n",
      "schoolid[T.12]    -0.3148      0.608     -0.518      0.605      -1.507       0.877\n",
      "schoolid[T.13]     0.1251      0.305      0.411      0.681      -0.472       0.722\n",
      "schoolid[T.14]    -0.5678      0.499     -1.137      0.255      -1.546       0.411\n",
      "schoolid[T.15]    -0.0465      0.206     -0.226      0.821      -0.450       0.357\n",
      "schoolid[T.16]    -0.0633      0.155     -0.408      0.683      -0.367       0.241\n",
      "schoolid[T.17]     0.1698      0.270      0.629      0.529      -0.359       0.699\n",
      "schoolid[T.18]    -0.1548      0.291     -0.531      0.595      -0.726       0.416\n",
      "schoolid[T.19]     0.0312      0.199      0.157      0.876      -0.360       0.422\n",
      "schoolid[T.20]    -0.1827      0.183     -0.999      0.318      -0.541       0.176\n",
      "schoolid[T.21]    -0.1323      0.230     -0.575      0.565      -0.583       0.319\n",
      "schoolid[T.22]    -0.5057      0.500     -1.012      0.312      -1.485       0.474\n",
      "schoolid[T.23]     0.0841      0.284      0.296      0.768      -0.473       0.642\n",
      "schoolid[T.24]    -0.1884      0.254     -0.740      0.459      -0.687       0.310\n",
      "schoolid[T.25]     0.1625      0.125      1.299      0.194      -0.083       0.408\n",
      "schoolid[T.26]    -0.0126      0.163     -0.077      0.938      -0.333       0.308\n",
      "schoolid[T.27]    -0.1868      0.201     -0.931      0.352      -0.580       0.206\n",
      "schoolid[T.28]    -0.3270      0.256     -1.279      0.201      -0.828       0.174\n",
      "schoolid[T.29]    -0.1390      0.209     -0.665      0.506      -0.549       0.271\n",
      "schoolid[T.30]    -0.2203      0.223     -0.988      0.323      -0.657       0.217\n",
      "schoolid[T.31]     0.0599      0.551      0.109      0.913      -1.019       1.139\n",
      "schoolid[T.32]     0.2081      0.301      0.691      0.489      -0.382       0.798\n",
      "schoolid[T.33]     0.0893      0.297      0.301      0.764      -0.492       0.671\n",
      "schoolid[T.34]     0.0015      0.167      0.009      0.993      -0.327       0.330\n",
      "schoolid[T.35]    -0.2075      0.307     -0.676      0.499      -0.810       0.394\n",
      "schoolid[T.36]    -0.1128      0.320     -0.352      0.724      -0.740       0.515\n",
      "schoolid[T.37]     0.1019      0.203      0.503      0.615      -0.295       0.499\n",
      "schoolid[T.38]    -0.1892      0.368     -0.514      0.607      -0.911       0.532\n",
      "schoolid[T.39]    -0.4546      0.279     -1.632      0.103      -1.001       0.091\n",
      "schoolid[T.40]    -0.3965      0.342     -1.159      0.246      -1.067       0.274\n",
      "schoolid[T.41]    -0.1506      0.365     -0.413      0.680      -0.865       0.564\n",
      "schoolid[T.42]     0.0150      0.261      0.058      0.954      -0.496       0.526\n",
      "schoolid[T.43]    -0.4523      0.332     -1.362      0.173      -1.103       0.199\n",
      "schoolid[T.44]     0.0330      0.278      0.119      0.906      -0.511       0.577\n",
      "schoolid[T.45]     0.0313      0.203      0.154      0.878      -0.367       0.429\n",
      "schoolid[T.46]    -0.1699      0.260     -0.654      0.513      -0.679       0.339\n",
      "schoolid[T.47]    -0.0738      0.128     -0.578      0.563      -0.324       0.177\n",
      "schoolid[T.48]    -0.2148      0.242     -0.886      0.376      -0.690       0.260\n",
      "schoolid[T.49]    -0.0828      0.234     -0.354      0.723      -0.541       0.376\n",
      "schoolid[T.50]     0.0620      0.315      0.197      0.844      -0.556       0.680\n",
      "schoolid[T.51]     0.4486      0.356      1.260      0.208      -0.249       1.146\n",
      "schoolid[T.52]    -0.1985      0.322     -0.616      0.538      -0.830       0.433\n",
      "schoolid[T.53]    -0.1075      0.378     -0.284      0.776      -0.849       0.634\n",
      "schoolid[T.54]    -0.0828      0.331     -0.251      0.802      -0.731       0.565\n",
      "schoolid[T.55]    -0.1754      0.464     -0.378      0.705      -1.084       0.733\n",
      "schoolid[T.56]     0.0127      0.374      0.034      0.973      -0.721       0.746\n",
      "schoolid[T.57]     0.1296      0.155      0.836      0.403      -0.174       0.433\n",
      "schoolid[T.58]     0.1145      0.189      0.607      0.544      -0.255       0.485\n",
      "schoolid[T.59]     0.1475      0.192      0.770      0.441      -0.228       0.523\n",
      "schoolid[T.60]    -0.0498      0.333     -0.150      0.881      -0.702       0.602\n",
      "schoolid[T.61]    -0.0119      0.200     -0.059      0.953      -0.404       0.380\n",
      "schoolid[T.62]     0.0607      0.125      0.484      0.628      -0.185       0.307\n",
      "schoolid[T.63]    -0.0133      0.259     -0.051      0.959      -0.521       0.495\n",
      "schoolid[T.64]     0.0201      0.132      0.152      0.879      -0.239       0.280\n",
      "schoolid[T.65]     0.0016      0.302      0.005      0.996      -0.591       0.594\n",
      "schoolid[T.66]    -0.1804      0.228     -0.790      0.430      -0.628       0.267\n",
      "schoolid[T.67]    -0.0529      0.148     -0.357      0.721      -0.343       0.237\n",
      "schoolid[T.68]    -0.2452      0.296     -0.829      0.407      -0.825       0.334\n",
      "schoolid[T.69]    -0.1772      0.148     -1.197      0.231      -0.467       0.113\n",
      "schoolid[T.70]    -0.1505      0.453     -0.332      0.740      -1.039       0.738\n",
      "schoolid[T.71]    -0.0876      0.303     -0.289      0.772      -0.681       0.506\n",
      "schoolid[T.72]     0.0071      0.149      0.048      0.962      -0.285       0.299\n",
      "schoolid[T.73]    -0.1388      0.136     -1.024      0.306      -0.404       0.127\n",
      "schoolid[T.74]    -0.0413      0.197     -0.209      0.834      -0.427       0.345\n",
      "schoolid[T.75]    -0.1982      0.352     -0.563      0.574      -0.888       0.492\n",
      "schoolid[T.76]     0.0166      0.165      0.101      0.920      -0.306       0.340\n",
      "S3                 0.1036      0.020      5.250      0.000       0.065       0.142\n",
      "C1                -0.0016      0.005     -0.295      0.768      -0.012       0.009\n",
      "C2                -0.1039      0.042     -2.449      0.014      -0.187      -0.021\n",
      "C3                -0.1319      0.046     -2.856      0.004      -0.222      -0.041\n",
      "XC                 0.0256      0.030      0.848      0.397      -0.034       0.085\n",
      "X1                -0.0720      0.056     -1.290      0.197      -0.181       0.037\n",
      "X2                 0.0220      0.049      0.453      0.651      -0.073       0.117\n",
      "X3                 0.0993      0.081      1.230      0.219      -0.059       0.258\n",
      "X4                -0.0050      0.037     -0.135      0.893      -0.078       0.068\n",
      "X5                -0.0284      0.072     -0.395      0.693      -0.169       0.113\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = smf.glm(formula = formula, data=data_all3, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7250b2",
   "metadata": {},
   "source": [
    "* Grow a forest. Add extra trees for the causal forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ce1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = DF[\"Z\"]\n",
    "Y = data_all[\"Z\"]\n",
    "X_raw = DF.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20956e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S3', 'C1', 'C2', 'C3', 'XC', 'X1', 'X2', 'X3', 'X4', 'X5'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_exp = pd.get_dummies(DF[\"C1\"],prefix = \"C1\")\n",
    "XC_exp = pd.get_dummies(DF[\"XC\"],prefix = \"XC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52075bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_raw.drop(columns=[\"C1\",\"XC\"]),C1_exp,XC_exp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67120662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S3', 'C2', 'C3', 'X1', 'X2', 'X3', 'X4', 'X5', 'C1_1', 'C1_2', 'C1_3',\n",
       "       'C1_4', 'C1_5', 'C1_6', 'C1_7', 'C1_8', 'C1_9', 'C1_10', 'C1_11',\n",
       "       'C1_12', 'C1_13', 'C1_14', 'C1_15', 'XC_0', 'XC_1', 'XC_2', 'XC_3',\n",
       "       'XC_4'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e42e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<econml.dml.causal_forest.CausalForestDML at 0x136f78350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing data to fit a causal forest\n",
    "fmla = 'schoolid + S3+ C1+ C2+ C3+ XC+ X1+ X2+ X3+ X4+ X5'\n",
    "desc = patsy.ModelDesc.from_formula(fmla)\n",
    "desc.describe()\n",
    "matrix = patsy.dmatrix(fmla, data_all, return_type = \"dataframe\")\n",
    "\n",
    "W = DF[\"Z\"] #treatment\n",
    "#Y = data_all[\"Z\"] #post-treatment\n",
    "Y = DF['Y']\n",
    "#X_raw = DF.iloc[:,2:]\n",
    "X = matrix\n",
    "W_n = None\n",
    "\n",
    "# Estimate a causal forest.\n",
    "est2 = CausalForestDML(model_t=RegressionForest(),\n",
    "                       model_y=RegressionForest(),\n",
    "                       n_estimators=200, min_samples_leaf=5,\n",
    "                       max_depth=50,\n",
    "                       verbose=0, random_state=123)\n",
    "\n",
    "est2.tune(Y, W, X=X, W=W_n)\n",
    "est2.fit(Y, W, X=X, W=W_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40494120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get residuals  and propensity \n",
    "residuals = est2.fit(Y, W, X=X, W=W_n, cache_values=True).residuals_\n",
    "W_res = residuals[1]\n",
    "e_hat = W - W_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86905784",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prop = pd.DataFrame({\"p_score\":e_hat, \"Treatment\":W})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_hat = est2.effect(X=X) # tau(X) estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c0c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27387535, 0.24592375, 0.25906053, ..., 0.19462195, 0.19472672,\n",
       "       0.18980818])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tau_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26758ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.61245189e-04, 0.00000000e+00, 1.96229324e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.72255634e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.18442318e-03, 0.00000000e+00, 0.00000000e+00, 3.06974587e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.48286137e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.87070829e-04, 4.40583547e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 8.13976838e-04, 0.00000000e+00, 7.28629552e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.52387586e-05,\n",
       "       1.12022728e-03, 6.34251974e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.38918711e-02, 1.17726352e-01, 6.60012221e-02, 3.59633340e-02,\n",
       "       3.32754416e-02, 2.31751580e-01, 1.35044789e-01, 7.45509898e-02,\n",
       "       8.67073067e-02, 1.80997479e-01])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est2.feature_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({\"covariaties\" : list(X.columns), \"values\" : est2.feature_importances()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16131d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covariaties</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>X1</td>\n",
       "      <td>0.231752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>X5</td>\n",
       "      <td>0.180997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>X2</td>\n",
       "      <td>0.135045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>C1</td>\n",
       "      <td>0.117726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>X4</td>\n",
       "      <td>0.086707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>schoolid[T.31]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>schoolid[T.30]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>schoolid[T.29]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>schoolid[T.27]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>schoolid[T.44]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       covariaties    values\n",
       "81              X1  0.231752\n",
       "85              X5  0.180997\n",
       "82              X2  0.135045\n",
       "77              C1  0.117726\n",
       "84              X4  0.086707\n",
       "..             ...       ...\n",
       "30  schoolid[T.31]  0.000000\n",
       "29  schoolid[T.30]  0.000000\n",
       "28  schoolid[T.29]  0.000000\n",
       "26  schoolid[T.27]  0.000000\n",
       "43  schoolid[T.44]  0.000000\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance.sort_values('values', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa678390",
   "metadata": {},
   "source": [
    "Data-driven subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16881af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fmla = 'schoolid + S3+ C1+ C2+ C3+ XC+ X1+ X2+ X3+ X4+ X5'\n",
    "fmla = '0+ schoolid + S3+ C1+ C2+ C3+ XC+ X1+ X2+ X3+ X4+ X5'\n",
    "desc = patsy.ModelDesc.from_formula(fmla)\n",
    "desc.describe()\n",
    "matrix = patsy.dmatrix(fmla, data_all, return_type = \"dataframe\")\n",
    "\n",
    "W = DF[\"Z\"] #treatment\n",
    "#Y = data_all[\"Z\"] #post-treatment\n",
    "Y = DF[\"Y\"] #post-treatment\n",
    "#X_raw = DF.iloc[:,2:]\n",
    "W_n = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_causal_forest(Y,T, X, W,  cluster):        \n",
    "        \n",
    "        base = pd.concat([Y,T], axis = 1)\n",
    "        \n",
    "        for i in range(cluster):\n",
    "        \n",
    "            index=range(X.shape[0]) \n",
    "            a = np.array_split(np.array(index),cluster)[i]  ## split index\n",
    "            \n",
    "            Y = base.drop(base.iloc[list(a),:].index).iloc[:,0]\n",
    "            T = base.drop(base.iloc[list(a),:].index).iloc[:,1]\n",
    "            XX = X.drop(X.iloc[list(a),:].index)\n",
    "            causal = CausalForestDML(model_t=RegressionForest(),\n",
    "                       model_y=RegressionForest(),\n",
    "                       n_estimators=200, min_samples_leaf=5,\n",
    "                       max_depth=50,\n",
    "                       verbose=0, random_state=123)\n",
    "            causal.fit(Y, T, X=XX, W=W)\n",
    "            \n",
    "            tau_hat = causal.effect(X=X.iloc[list(a),:]) # tau(X) estimates using validation data\n",
    "            vector = i*np.ones( len(list(a)) ) + 1\n",
    "            globals()[f'data_{i}'] = pd.DataFrame({\"tau_hat\":tau_hat, \"Cluster\":vector})\n",
    "       \n",
    "        tau_predict = data_0.copy()\n",
    "\n",
    "        for k in range(1,10):\n",
    "            tau_predict = tau_predict.concat(globals()[f'data_{k}'] , ignore_index=True)\n",
    "        \n",
    "        return tau_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae81d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "num_rankings = 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda6e9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/bp/p_j4tl057jbbd0cmp6xbd9pw0000gn/T/ipykernel_15144/2436848413.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtau_hat_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_causal_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_n\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ranking'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/var/folders/bp/p_j4tl057jbbd0cmp6xbd9pw0000gn/T/ipykernel_15144/2136244812.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(Y, T, X, W, cluster)\u001b[0m\n",
      "\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     24\u001b[0m         \u001b[0mtau_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mtau_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtau_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'data_{k}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtau_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/Downloads/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n",
      "\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   6202\u001b[0m         ):\n",
      "\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "tau_hat_cluster = cluster_causal_forest(Y,W, X, W_n,  cluster = num_folds)\n",
    "\n",
    "data_all['ranking'] = np.nan\n",
    "\n",
    "for i in range(1,num_folds+1):\n",
    "    split = tau_hat_cluster.Cluster == i\n",
    "    index = tau_hat_cluster[split].index\n",
    "    tau_quantile = np.quantile(tau_hat_cluster[split].iloc[:,0], list(np.arange(0,1.1,0.2)))\n",
    "    labels =[i for i in range(1,6)]\n",
    "    data.loc[index , [\"ranking\"]] = pd.cut(tau_hat_cluster[split][\"tau_hat\"], \n",
    "                                               tau_quantile , right=False, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5f430",
   "metadata": {},
   "source": [
    "## 2. Estimate ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8160e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for the ATE: 0.226 +/- 0.485\n"
     ]
    }
   ],
   "source": [
    "ATE = est2.effect(X)\n",
    "# Calcular el intervalo de confianza del 95% para el ATE\n",
    "ci_lower = ATE[1] - norm.ppf(0.975) * ATE[2]\n",
    "ci_upper = ATE[1] + norm.ppf(0.975) * ATE[2]\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(\"95% CI for the ATE:\", round(ATE[1], 3),\n",
    "      \"+/-\", round(norm.ppf(0.975) * ATE[2], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54793ae4",
   "metadata": {},
   "source": [
    "With the tuned parameters, we estimate the average treatment effect (ATE) that is 0.226 and has a confidence interval (+/-0.0485) with a 95/% confidence. This means that the effect of the treatment or the intervetion related to the growth mind set had a positive and significant impact on the measure of achievement of the students on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec304ba",
   "metadata": {},
   "source": [
    "## 3. Run best linear predictor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88794a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_hat = est2.effect(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79294ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing AIPW scores.\n",
    "tau_hat = est2.effect(X=X) #E[Y|X]\n",
    "\n",
    "residuals = est2.fit(Y, W, X=X, W=W_n, cache_values=True).residuals_\n",
    "W_res = residuals[1]\n",
    "e_hat = W - W_res  # P[W=1|X]\n",
    "\n",
    "Y_res = residuals[0]\n",
    "m_hat = Y - Y_res # E[Y|X]\n",
    "\n",
    "mu_hat0 = m_hat - e_hat * tau_hat        # E[Y|X,W=0] = E[Y|X] - e(X)*tau(X)\n",
    "mu_hat1 = m_hat + (1 - e_hat) * tau_hat  # E[Y|X,W=1] = E[Y|X] + (1 - e(X))*tau(X)\n",
    "\n",
    "# AIPW scores\n",
    "data_all['aipw_scores'] = tau_hat + W / e_hat * (Y -  mu_hat1) - (1 - W) / (1 - e_hat) * (Y -  mu_hat0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732838cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4dce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['m_hat'] = m_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2d54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance of constraints does not have full rank. The number of constraints is 85, but rank is 80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef.</th>\n",
       "      <th>Std.Err.</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-1.164420</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>-72.236890</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.196014</td>\n",
       "      <td>-1.132827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolid[T.2]</th>\n",
       "      <td>0.059962</td>\n",
       "      <td>0.011997</td>\n",
       "      <td>4.997993</td>\n",
       "      <td>5.793009e-07</td>\n",
       "      <td>0.036448</td>\n",
       "      <td>0.083477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolid[T.3]</th>\n",
       "      <td>0.092527</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>9.257676</td>\n",
       "      <td>2.089294e-20</td>\n",
       "      <td>0.072938</td>\n",
       "      <td>0.112116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolid[T.4]</th>\n",
       "      <td>-0.019255</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>-1.775899</td>\n",
       "      <td>7.574956e-02</td>\n",
       "      <td>-0.040506</td>\n",
       "      <td>0.001996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolid[T.5]</th>\n",
       "      <td>0.024309</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>1.737416</td>\n",
       "      <td>8.231375e-02</td>\n",
       "      <td>-0.003114</td>\n",
       "      <td>0.051732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>-0.066211</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>-17.241730</td>\n",
       "      <td>1.291148e-66</td>\n",
       "      <td>-0.073737</td>\n",
       "      <td>-0.058684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>-0.030225</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>-9.400628</td>\n",
       "      <td>5.423859e-21</td>\n",
       "      <td>-0.036526</td>\n",
       "      <td>-0.023923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>0.027256</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>5.611318</td>\n",
       "      <td>2.007910e-08</td>\n",
       "      <td>0.017736</td>\n",
       "      <td>0.036776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.821678</td>\n",
       "      <td>4.112604e-01</td>\n",
       "      <td>-0.003198</td>\n",
       "      <td>0.007814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>0.041985</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>9.474063</td>\n",
       "      <td>2.691668e-21</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.050670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Coef.  Std.Err.          z         P>|z|    [0.025    0.975]\n",
       "Intercept     -1.164420  0.016119 -72.236890  0.000000e+00 -1.196014 -1.132827\n",
       "schoolid[T.2]  0.059962  0.011997   4.997993  5.793009e-07  0.036448  0.083477\n",
       "schoolid[T.3]  0.092527  0.009995   9.257676  2.089294e-20  0.072938  0.112116\n",
       "schoolid[T.4] -0.019255  0.010842  -1.775899  7.574956e-02 -0.040506  0.001996\n",
       "schoolid[T.5]  0.024309  0.013992   1.737416  8.231375e-02 -0.003114  0.051732\n",
       "...                 ...       ...        ...           ...       ...       ...\n",
       "X1            -0.066211  0.003840 -17.241730  1.291148e-66 -0.073737 -0.058684\n",
       "X2            -0.030225  0.003215  -9.400628  5.423859e-21 -0.036526 -0.023923\n",
       "X3             0.027256  0.004857   5.611318  2.007910e-08  0.017736  0.036776\n",
       "X4             0.002308  0.002809   0.821678  4.112604e-01 -0.003198  0.007814\n",
       "X5             0.041985  0.004432   9.474063  2.691668e-21  0.033299  0.050670\n",
       "\n",
       "[86 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smf.ols('m_hat ~ schoolid + S3+ C1+ C2+ C3+ XC+ X1+ X2+ X3+ X4+ X5',d).fit(cov_type = 'HC3').summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d97221",
   "metadata": {},
   "source": [
    "It finds that if we insists in cluster-robust inference, there's almost no treatment heterogenity present and thus that the causal forest couldn't identify subgroups with effects at stand.\n",
    "\n",
    "Due to this, they try to found if there's heterogenity between two specific variables: pre-existing mindset and school-level achievement. They find that schools with larger values of pre-existing mindset have larger effects than schools with smaller values of this variables. However, they do not see much heterogeneity along school-level achievement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982eb714",
   "metadata": {},
   "source": [
    "##  4. Look at school-wise heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f6966",
   "metadata": {},
   "source": [
    "As seen before, there's much perceivable heterogenety at school-level. In order to see if this help us to identify heteregenous effects, we fit models using only school-level covariates. This fact seems to be presented on the next graphs, where the distribution of the school treatment effects and the student expectation success propensity score are shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1cc584",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_score = school_mat / school_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b6351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))  # Configura el tamaÃ±o de la figura\n",
    "plt.rcParams.update({'axes.labelsize': 15, 'xtick.labelsize': 15, 'ytick.labelsize': 15, 'axes.titlesize': 15})\n",
    "\n",
    "# Crear el histograma\n",
    "plt.hist(school_score, bins=10, edgecolor='black')\n",
    "\n",
    "# Etiquetas y tÃ­tulo\n",
    "plt.xlabel('School Treatment Effect Estimate')\n",
    "plt.title('')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b399731",
   "metadata": {},
   "source": [
    "## 5. Analysis ignoring clusters. How do the results change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45969055",
   "metadata": {},
   "source": [
    "We have seen until now no evidence on heteregenious effects of the treatment considering clusters. This mean we have token into account the possible correlation between students that attend the same school. Althought it will be naive to be believed that this doesn't happend, it will helpful to analyse whether there exist consistent difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576aeae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[311], line 7\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m estimator \u001b[38;5;241m=\u001b[39m CausalForestDML(model_t\u001b[38;5;241m=\u001b[39mRandomForestRegressor(),\n",
      "\u001b[1;32m      2\u001b[0m                             model_y\u001b[38;5;241m=\u001b[39mRandomForestRegressor(),\n",
      "\u001b[1;32m      3\u001b[0m                             discrete_treatment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[1;32m      4\u001b[0m                             n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Ajuste del modelo causal\u001b[39;00m\n",
      "\u001b[0;32m----> 7\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(Y, W, X\u001b[38;5;241m=\u001b[39mX)\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# EstimaciÃ³n del ATE\u001b[39;00m\n",
      "\u001b[1;32m     10\u001b[0m ATE_noclust \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mate(X)\n",
      "\n",
      "File \u001b[0;32m~/Downloads/anaconda3/lib/python3.11/site-packages/econml/dml/causal_forest.py:854\u001b[0m, in \u001b[0;36mCausalForestDML.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, groups, cache_values, inference)\u001b[0m\n",
      "\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis estimator does not support X=None!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(Y, T, X\u001b[38;5;241m=\u001b[39mX, W\u001b[38;5;241m=\u001b[39mW,\n",
      "\u001b[1;32m    855\u001b[0m                    sample_weight\u001b[38;5;241m=\u001b[39msample_weight, groups\u001b[38;5;241m=\u001b[39mgroups,\n",
      "\u001b[1;32m    856\u001b[0m                    cache_values\u001b[38;5;241m=\u001b[39mcache_values,\n",
      "\u001b[1;32m    857\u001b[0m                    inference\u001b[38;5;241m=\u001b[39minference)\n",
      "\n",
      "File \u001b[0;32m~/Downloads/anaconda3/lib/python3.11/site-packages/econml/dml/_rlearner.py:422\u001b[0m, in \u001b[0;36m_RLearner.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n",
      "\u001b[1;32m    385\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03mEstimate the counterfactual model from data, i.e. estimates function :math:`\\\\theta(\\\\cdot)`.\u001b[39;00m\n",
      "\u001b[1;32m    387\u001b[0m \n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03mself: _RLearner instance\u001b[39;00m\n",
      "\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# Replacing fit from _OrthoLearner, to enforce Z=None and improve the docstring\u001b[39;00m\n",
      "\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(Y, T, X\u001b[38;5;241m=\u001b[39mX, W\u001b[38;5;241m=\u001b[39mW,\n",
      "\u001b[1;32m    423\u001b[0m                    sample_weight\u001b[38;5;241m=\u001b[39msample_weight, freq_weight\u001b[38;5;241m=\u001b[39mfreq_weight, sample_var\u001b[38;5;241m=\u001b[39msample_var, groups\u001b[38;5;241m=\u001b[39mgroups,\n",
      "\u001b[1;32m    424\u001b[0m                    cache_values\u001b[38;5;241m=\u001b[39mcache_values,\n",
      "\u001b[1;32m    425\u001b[0m                    inference\u001b[38;5;241m=\u001b[39minference)\n",
      "\n",
      "File \u001b[0;32m~/Downloads/anaconda3/lib/python3.11/site-packages/econml/_cate_estimator.py:131\u001b[0m, in \u001b[0;36mBaseCateEstimator._wrap_fit.<locals>.call\u001b[0;34m(self, Y, T, inference, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    129\u001b[0m     inference\u001b[38;5;241m.\u001b[39mprefit(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# call the wrapped fit method\u001b[39;00m\n",
      "\u001b[0;32m--> 131\u001b[0m m(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postfit(Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# NOTE: we call inference fit *after* calling the main fit method\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Downloads/anaconda3/lib/python3.11/site-packages/econml/_ortho_learner.py:761\u001b[0m, in \u001b[0;36m_OrthoLearner.fit\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, freq_weight, sample_var, groups, cache_values, inference, only_final, check_input)\u001b[0m\n",
      "\u001b[1;32m    757\u001b[0m     X, \u001b[38;5;241m=\u001b[39m check_input_arrays(\n",
      "\u001b[1;32m    758\u001b[0m         X, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_allowed_missing_vars() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;32m    759\u001b[0m     W, \u001b[38;5;241m=\u001b[39m check_input_arrays(\n",
      "\u001b[1;32m    760\u001b[0m         W, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_allowed_missing_vars() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;32m--> 761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_dims(Y, T, X, W, Z, sample_weight, freq_weight, sample_var, groups)\n",
      "\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_final:\n",
      "\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscrete_outcome:\n",
      "\n",
      "File \u001b[0;32m~/Downloads/anaconda3/lib/python3.11/site-packages/econml/_ortho_learner.py:652\u001b[0m, in \u001b[0;36m_OrthoLearner._check_input_dims\u001b[0;34m(self, Y, T, X, W, Z, *other_arrays)\u001b[0m\n",
      "\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m shape(Y)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m shape(T)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension mis-match!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m [X, W, Z, \u001b[38;5;241m*\u001b[39mother_arrays]:\n",
      "\u001b[0;32m--> 652\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (arr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_d_x \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    654\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_d_w \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m W \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dimension mismatch"
     ]
    }
   ],
   "source": [
    "estimator = CausalForestDML(model_t=RandomForestRegressor(),\n",
    "                            model_y=RandomForestRegressor(),\n",
    "                            discrete_treatment=True,\n",
    "                            n_estimators=100)\n",
    "\n",
    "# Ajuste del modelo causal\n",
    "estimator.fit(Y, W, X=X)\n",
    "\n",
    "# EstimaciÃ³n del ATE\n",
    "ATE_noclust = estimator.ate(X)\n",
    "ATE_mean = ATE_noclust[0]\n",
    "ATE_ci = norm.ppf(0.975) * ATE_noclust[1]\n",
    "\n",
    "print(f\"95% CI for the ATE: {ATE_mean:.3f} +/- {ATE_ci:.3f}\")\n",
    "\n",
    "# PredicciÃ³n tau.hat.noclust\n",
    "tau_hat_noclust = estimator.effect(X)\n",
    "\n",
    "# Plot de school.id vs tau.hat.noclust\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(school_id, tau_hat_noclust)\n",
    "plt.xlabel(\"School ID\")\n",
    "plt.ylabel(\"Tau Hat (No Clustering)\")\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation para tau.hat.crossfold\n",
    "nfold = 5\n",
    "school_levels = np.unique(school_id)\n",
    "cluster_folds = np.random.randint(1, nfold + 1, size=len(school_levels))\n",
    "\n",
    "tau_hat_crossfold = np.full(len(Y), np.nan)\n",
    "for foldid in range(1, nfold + 1):\n",
    "    print(foldid)\n",
    "    infold = np.isin(school_id, school_levels[cluster_folds == foldid])\n",
    "    \n",
    "    X_train, X_test = X[~infold], X[infold]\n",
    "    Y_train, Y_test = Y[~infold], Y[infold]\n",
    "    W_train, W_test = W[~infold], W[infold]\n",
    "    Y_hat_train, W_hat_train = Y_hat[~infold], W_hat[~infold]\n",
    "    \n",
    "    estimator_fold = C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67e209",
   "metadata": {},
   "source": [
    "## 6. Analysis without fitting the propensity score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ceb13",
   "metadata": {},
   "source": [
    "We see that propensity score is not as important to the results found as clsutering was since it appers to be that the ATE found (0.254) is very much similar to the one found using orthogalization. As we can see in the followin figure, the overlaped distribution are almost the same because they are really close to the 45 degree line that means equiality between the two variables (that are the estimates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb827a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_noprop = CausalForestDML(model_t=RandomForestRegressor(),\n",
    "                            model_y=RandomForestRegressor(),\n",
    "                            discrete_treatment=True,\n",
    "                            n_estimators=100,\n",
    "                            equalize_cluster_weights=True,\n",
    "                            clusters=school_id)\n",
    "\n",
    "cf_noprop.fit(Y, W, X=X, W_hat=np.mean(W), Y_hat=Y_hat)\n",
    "\n",
    "\n",
    "ATE_noprop = cf_noprop.ate(X)\n",
    "ATE_mean_noprop = ATE_noprop[0]\n",
    "ATE_ci_noprop = norm.ppf(0.975) * ATE_noprop[1]\n",
    "\n",
    "print(f\"95% CI for the ATE (noprop): {ATE_mean_noprop:.3f} +/- {ATE_ci_noprop:.3f}\")\n",
    "\n",
    "\n",
    "tau_hat_noprop = cf_noprop.effect(X)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(tau_hat, tau_hat_noprop)\n",
    "plt.xlim(min(tau_hat), max(tau_hat))\n",
    "plt.ylim(min(tau_hat), max(tau_hat))\n",
    "plt.xlabel(\"orthogonalized causal forest estimates\")\n",
    "plt.ylabel(\"non-orthogonalized causal forest\")\n",
    "plt.plot([min(tau_hat), max(tau_hat)], [min(tau_hat), max(tau_hat)], linestyle=\"--\", linewidth=2, color=\"r\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "school_X = np.dot(np.transpose(school.mat), X[:, [3, 4, 5, 6, 7, 24, 25, 26, 27, 28]]) / school.size\n",
    "school_X = pd.DataFrame(school_X, columns=[\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"XC.1\", \"XC.2\", \"XC.3\", \"XC.4\"])\n",
    "\n",
    "dr_score = tau_hat + W / cf.W_hat * (Y - cf.Y_hat - (1 - cf.W_hat) * tau_hat) - (1 - W) / (1 - cf.W_hat) * (Y - cf.Y_hat + cf.W_hat * tau_hat)\n",
    "school_score = np.dot(np.transpose(school.mat), dr_score) / school.size\n",
    "\n",
    "school_forest = RandomForestRegressor()\n",
    "school_forest.fit(school_X, school_score)\n",
    "school_pred = school_forest.predict(school_X)\n",
    "\n",
    "\n",
    "school_DF = pd.concat([school_X, pd.Series(school_score, name='school_score')], axis=1)\n",
    "ols_model = sm.OLS(school_score, sm.add_constant(school_X)).fit()\n",
    "ols_results = ols_model.summary()\n",
    "\n",
    "print(ols_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265694b",
   "metadata": {},
   "source": [
    "## 7. The code plot six plots in the Make some plots section, so explain what you find there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "\n",
    "\n",
    "plt.hist(tau_hat, bins=20, edgecolor='black')\n",
    "plt.xlabel(\"estimated CATE\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of tau.hat\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(tau_hat_noprop, bins=20, edgecolor='black')\n",
    "plt.xlabel(\"estimated CATE\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of tau.hat.noprop\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(tau_hat_noclust, bins=np.arange(-0.0, 0.55, 0.55/25), edgecolor='black')\n",
    "plt.xlabel(\"estimated CATE\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of tau.hat.noclust\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.boxplot([tau_hat[X[:, 0] == i] for i in np.unique(X[:, 0].round())], labels=np.unique(X[:, 0].round()))\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"estimated CATE\")\n",
    "plt.title(\"Boxplot of tau.hat by X1\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.boxplot([tau_hat[X[:, 1] == i] for i in np.unique(X[:, 1].round())], labels=np.unique(X[:, 1].round()))\n",
    "plt.xlabel(\"X2\")\n",
    "plt.ylabel(\"estimated CATE\")\n",
    "plt.title(\"Boxplot of tau.hat by X2\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(school.avg.tauhat, school.pred, c='blue', s=50)\n",
    "plt.plot(school.avg.tauhat, school.avg.tauhat, linestyle='--', color='red', linewidth=2)\n",
    "plt.xlabel(\"average CATE estimate in school\")\n",
    "plt.ylabel(\"school-wise forest predictions\")\n",
    "plt.title(\"Scatter plot of school.avg.tauhat vs. school.pred\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "n_synth = 1000\n",
    "p_synth = 10\n",
    "X_synth = np.random.normal(size=(n_synth, p_synth))\n",
    "W_synth = np.random.binomial(1, 1 / (1 + np.exp(-X_synth[:, 0])), size=n_synth)\n",
    "Y_synth = 2 * np.mean(X_synth[:, :6], axis=1) + np.random.normal(size=n_synth)\n",
    "\n",
    "Y_forest_synth = RandomForestRegressor().fit(X_synth, Y_synth)\n",
    "Y_hat_synth = Y_forest_synth.predict(X_synth)\n",
    "W_forest_synth = RandomForestRegressor().fit(X_synth, W_synth)\n",
    "W_hat_synth = W_forest_synth.predict(X_synth)\n",
    "\n",
    "cf_synth = CausalForestDML(model_t=RandomForestRegressor(), model_y=RandomForestRegressor())\n",
    "cf_synth.fit(Y_synth, W_synth, X_synth, W_hat=W_hat_synth, Y_hat=Y_hat_synth)\n",
    "ATE_synth = cf_synth.ate(X_synth)\n",
    "\n",
    "cf_synth_noprop = CausalForestDML(model_t=RandomForestRegressor(), model_y=RandomForestRegressor())\n",
    "cf_synth_noprop.fit(Y_synth, W_synth, X_synth, W_hat=np.mean(W_synth), Y_hat=Y_hat_synth)\n",
    "ATE_synth_noprop = cf_synth_noprop.ate(X_synth)\n",
    "\n",
    "print(f\"95% CI for the ATE (synth): {round(ATE_synth[0], 3)} +/- {round(norm.ppf(0.975) * ATE_synth[1], 3)}\")\n",
    "print(f\"95% CI for the ATE (synth noprop): {round(ATE_synth_noprop[0], 3)} +/- {round(norm.ppf(0.975) * ATE_synth_noprop[1], 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f54b5f",
   "metadata": {},
   "source": [
    "## 8. Visualize school-level covariates by treatment heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "school.X_std = scaler.fit_transform(school.X)\n",
    "\n",
    "\n",
    "terciles = pd.cut(school.pred, bins=[-np.inf, school.pred.quantile(1/3), school.pred.quantile(2/3), np.inf],\n",
    "                  labels=[\"low\", \"mid\", \"high\"])\n",
    "school.tercile_mat = pd.get_dummies(terciles).values\n",
    "\n",
    "\n",
    "means = np.linalg.pinv(np.sum(school.tercile_mat, axis=0) * np.eye(school.tercile_mat.shape[1])) @ \\\n",
    "        school.tercile_mat.T @ school.X_std\n",
    "\n",
    "\n",
    "df_plot = pd.DataFrame({\"tercile\": np.repeat([\"low\", \"mid\", \"high\"], school.tercile_mat.shape[1]),\n",
    "                        \"mean\": means.flatten(),\n",
    "                        \"feature\": np.tile(school.X.columns, 3)})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_plot.pivot(\"tercile\", \"feature\", \"mean\"), cmap=\"coolwarm\", annot=True, fmt=\".2f\")\n",
    "plt.savefig(\"tercile_plot.pdf\")\n",
    "\n",
    "\n",
    "mean_XC_3 = np.mean(school.X[\"XC.3\"])\n",
    "mean_XC_3_low_tercile = np.mean(school.X[\"XC.3\"][terciles == \"low\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575cc13",
   "metadata": {},
   "source": [
    "This graph show us the difference between the mean of the CATE for each school-level covariate considered in the school-wise estimation. We can see that there is not much hetereginty between the means in all covariates but the X1, where the difference between the low and high group of CATEs. This reminds us that even if it seem to be variability in the effects when we divide by this covariate, there's not enough evidence that controling with the other covariates this effect will remain even when analysing the data at school-level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0132119",
   "metadata": {},
   "source": [
    "## 9. CATE by school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499754e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_indices = np.argsort(np.argsort(school.pred))\n",
    "school_sort = ord_indices[school.id]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(tau_hat_noclust, positions=school_sort, widths=0.5)\n",
    "plt.scatter(range(1, 77), np.sort(school.pred), color='red', marker='o', label='school mean CATE')\n",
    "plt.xlabel(\"school\")\n",
    "plt.ylabel(\"estimated CATE\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(\"school_boxplot.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492361f",
   "metadata": {},
   "source": [
    "This graph compares per-student predictions from a non-cluster-robust causal forest to per-school mean treatment effect predictions from a forest trained on per-school responses that takes clustering into account. As seen before. We can see that CATE found in when ignoring clusters is higher and more disperse by school than when considering clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
